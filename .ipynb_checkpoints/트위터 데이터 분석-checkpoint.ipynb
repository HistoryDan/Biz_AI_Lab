{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f3225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a545d6",
   "metadata": {},
   "source": [
    "# 1. 트위터 데이터 계정별로 통합하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f95c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '/Users/parkjunhyeong/Desktop/USB'\n",
    "# save_path = '/Users/parkjunhyeong/Desktop'\n",
    "# files = os.listdir(file_path)\n",
    "# files_n = []\n",
    "# for f in files:\n",
    "#     f = f[:-6]\n",
    "#     if f != '.DS':\n",
    "#         files_n.append(f)\n",
    "# files_n = set(files_n)\n",
    "\n",
    "# for f in tqdm(files_n):\n",
    "#     df0 = pd.read_csv(file_path + '/' + f + '-0.csv', index_col = 0)\n",
    "#     df1 = pd.read_csv(file_path + '/' + f + '-1.csv', index_col = 0)\n",
    "#     df2 = pd.read_csv(file_path + '/' + f + '-2.csv', index_col = 0)\n",
    "#     df3 = pd.read_csv(file_path + '/' + f + '-3.csv', index_col = 0)\n",
    "#     df4 = pd.read_csv(file_path + '/' + f + '-4.csv', index_col = 0)\n",
    "#     df5 = pd.read_csv(file_path + '/' + f + '-5.csv', index_col = 0)\n",
    "#     df6 = pd.read_csv(file_path + '/' + f + '-6.csv', index_col = 0)\n",
    "#     df10 = pd.concat([df0,df1,df2,df3,df4,df5,df6,df7,df8,df9], axis = 0)\n",
    "#     df10.sort_values(by = 'datetime', inplace = True)\n",
    "#     df10.reset_index(inplace = True, drop = True)\n",
    "#     df10.to_csv(save_path + '/' + f +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435eab39",
   "metadata": {},
   "source": [
    "# 2. 연구 대상 트위터 데이터만 선별하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa4b72eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#기사 제목으로 필터링한 일반 뉴스 (비즈니스 뉴스 제외)\n",
    "df1 = pd.read_excel('/Users/parkjunhyeong/Desktop/nytimes2_ver0.1.xlsx', sheet_name = 'Sheet1')\n",
    "#기사 제목으로 필터링한 비즈니스 뉴스\n",
    "df2 = pd.read_excel('/Users/parkjunhyeong/Desktop/nytimes_ver1.1.xlsx', sheet_name = 'Sheet1')\n",
    "#Russell 1000 메타 데이터\n",
    "meta = pd.read_excel('/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/01. 메타 데이터/Russell_1000_combined_v0.4.xlsx', sheet_name = 'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c440e55b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#연구대상 기업 Ticker들만 추리기\n",
    "tickers = []\n",
    "for i in range(len(df1)):\n",
    "    tickers.extend(eval(df1['Ticker'][i]))\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    tickers.extend(eval(df2['Ticker'][i]))\n",
    "    \n",
    "tickers = set(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b94011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AAL',\n",
       " 'AAPL',\n",
       " 'ABBV',\n",
       " 'ABNB',\n",
       " 'ABT',\n",
       " 'ACI',\n",
       " 'ACN',\n",
       " 'ADBE',\n",
       " 'AFRM',\n",
       " 'ALK',\n",
       " 'ALSN',\n",
       " 'AMC',\n",
       " 'AMZN',\n",
       " 'AN',\n",
       " 'AON',\n",
       " 'ATVI',\n",
       " 'AVGO',\n",
       " 'AVY',\n",
       " 'AXON',\n",
       " 'AXP',\n",
       " 'BA',\n",
       " 'BAC',\n",
       " 'BBY',\n",
       " 'BIIB',\n",
       " 'BK',\n",
       " 'BLK',\n",
       " 'BMY',\n",
       " 'BX',\n",
       " 'C',\n",
       " 'CAT',\n",
       " 'CC',\n",
       " 'CCL',\n",
       " 'CG',\n",
       " 'CHTR',\n",
       " 'CLX',\n",
       " 'CMCSA',\n",
       " 'CMG',\n",
       " 'CNC',\n",
       " 'COF',\n",
       " 'COIN',\n",
       " 'COP',\n",
       " 'COTY',\n",
       " 'CPRI',\n",
       " 'CRM',\n",
       " 'CRWD',\n",
       " 'CSCO',\n",
       " 'CVS',\n",
       " 'CVX',\n",
       " 'CZR',\n",
       " 'D',\n",
       " 'DAL',\n",
       " 'DASH',\n",
       " 'DD',\n",
       " 'DE',\n",
       " 'DELL',\n",
       " 'DG',\n",
       " 'DIS',\n",
       " 'DKNG',\n",
       " 'DLTR',\n",
       " 'DOV',\n",
       " 'DPZ',\n",
       " 'EBAY',\n",
       " 'EFX',\n",
       " 'EL',\n",
       " 'EMR',\n",
       " 'ETR',\n",
       " 'ETSY',\n",
       " 'F',\n",
       " 'FDX',\n",
       " 'FIS',\n",
       " 'FITB',\n",
       " 'FOX',\n",
       " 'FSLR',\n",
       " 'GE',\n",
       " 'GILD',\n",
       " 'GM',\n",
       " 'GME',\n",
       " 'GOOG',\n",
       " 'GPS',\n",
       " 'GS',\n",
       " 'HAS',\n",
       " 'HCA',\n",
       " 'HD',\n",
       " 'HLT',\n",
       " 'HOG',\n",
       " 'HON',\n",
       " 'HOOD',\n",
       " 'HPE',\n",
       " 'HPQ',\n",
       " 'HSY',\n",
       " 'HTZ',\n",
       " 'HUM',\n",
       " 'HUN',\n",
       " 'IAA',\n",
       " 'IBM',\n",
       " 'IDA',\n",
       " 'INTC',\n",
       " 'INTU',\n",
       " 'ITT',\n",
       " 'JBLU',\n",
       " 'JNJ',\n",
       " 'JPM',\n",
       " 'JWN',\n",
       " 'K',\n",
       " 'KHC',\n",
       " 'KKR',\n",
       " 'KO',\n",
       " 'KR',\n",
       " 'KSS',\n",
       " 'L',\n",
       " 'LAZ',\n",
       " 'LCID',\n",
       " 'LLY',\n",
       " 'LMT',\n",
       " 'LOW',\n",
       " 'LPX',\n",
       " 'LULU',\n",
       " 'LUV',\n",
       " 'LYFT',\n",
       " 'LYV',\n",
       " 'M',\n",
       " 'MA',\n",
       " 'MAR',\n",
       " 'MAT',\n",
       " 'MCD',\n",
       " 'MCO',\n",
       " 'META',\n",
       " 'MGM',\n",
       " 'MMM',\n",
       " 'MO',\n",
       " 'MRK',\n",
       " 'MRNA',\n",
       " 'MS',\n",
       " 'MSFT',\n",
       " 'MTN',\n",
       " 'NCLH',\n",
       " 'NDAQ',\n",
       " 'NET',\n",
       " 'NFLX',\n",
       " 'NKE',\n",
       " 'NVAX',\n",
       " 'NVDA',\n",
       " 'NWS',\n",
       " 'NYT',\n",
       " 'OMC',\n",
       " 'ORCL',\n",
       " 'OXY',\n",
       " 'PARAA',\n",
       " 'PCG',\n",
       " 'PEP',\n",
       " 'PFE',\n",
       " 'PG',\n",
       " 'PINS',\n",
       " 'PLTR',\n",
       " 'PM',\n",
       " 'PNC',\n",
       " 'PSX',\n",
       " 'PTON',\n",
       " 'PYPL',\n",
       " 'QCOM',\n",
       " 'RBLX',\n",
       " 'RCL',\n",
       " 'REGN',\n",
       " 'RIVN',\n",
       " 'RL',\n",
       " 'ROKU',\n",
       " 'RTX',\n",
       " 'RUN',\n",
       " 'SBAC',\n",
       " 'SBUX',\n",
       " 'SCHW',\n",
       " 'SIRI',\n",
       " 'SKX',\n",
       " 'SPG',\n",
       " 'SPGI',\n",
       " 'SPOT',\n",
       " 'SRE',\n",
       " 'STT',\n",
       " 'T',\n",
       " 'TAP',\n",
       " 'TMO',\n",
       " 'TMUS',\n",
       " 'TRIP',\n",
       " 'TRU',\n",
       " 'TSLA',\n",
       " 'TSN',\n",
       " 'UA',\n",
       " 'UAL',\n",
       " 'UBER',\n",
       " 'UNH',\n",
       " 'UPS',\n",
       " 'USFD',\n",
       " 'V',\n",
       " 'VMW',\n",
       " 'VOYA',\n",
       " 'VSCO',\n",
       " 'VTRS',\n",
       " 'VZ',\n",
       " 'W',\n",
       " 'WBA',\n",
       " 'WBD',\n",
       " 'WE',\n",
       " 'WEN',\n",
       " 'WFC',\n",
       " 'WMT',\n",
       " 'WTW',\n",
       " 'WWD',\n",
       " 'WWE',\n",
       " 'X',\n",
       " 'XOM',\n",
       " 'ZG',\n",
       " 'ZM'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#연구 대상 티커들 확인\n",
    "print(len(tickers))\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d8c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#연구 대상 기업들의 트위터 계정명 추리기\n",
    "twitters = []\n",
    "for i in range(len(meta)):\n",
    "    twitters.append((meta['Ticker'][i], meta['Twitter Accounts'][i]))\n",
    "\n",
    "dic = defaultdict(set)\n",
    "\n",
    "for ticker, account in twitters:\n",
    "    dic[ticker].add(account)\n",
    "\n",
    "dic_n = {}\n",
    "for key in dic.keys():\n",
    "    if key in tickers:\n",
    "        dic_n[key] = dic[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a14c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MMM': {'@3M'},\n",
       " 'ABT': {'@AbbottNews'},\n",
       " 'ABBV': {'@abbvie'},\n",
       " 'ACN': {'@Accenture'},\n",
       " 'ATVI': {'@ATVI_AB'},\n",
       " 'ADBE': {'@Adobe'},\n",
       " 'AFRM': {'@Affirm'},\n",
       " 'ABNB': {'@Airbnb'},\n",
       " 'ALK': {'@AlaskaAir'},\n",
       " 'ACI': {'@Albertsons'},\n",
       " 'ALSN': {'@AllisonTrans'},\n",
       " 'GOOG': {'@Google'},\n",
       " 'MO': {'@AltriaNews'},\n",
       " 'AMZN': {'@amazon'},\n",
       " 'AMC': {'@AMCTheatres'},\n",
       " 'AAL': {'@AmericanAir'},\n",
       " 'AXP': {'@AmericanExpress'},\n",
       " 'AON': {'@Aon_plc'},\n",
       " 'AAPL': {'@Apple'},\n",
       " 'T': {'@ATT'},\n",
       " 'AN': {'@AutoNation'},\n",
       " 'AVY': {'@AveryDennison'},\n",
       " 'AXON': {'@axon_us'},\n",
       " 'BAC': {'@BankofAmerica'},\n",
       " 'BK': {'@BNYMellon'},\n",
       " 'BBY': {'@BestBuy'},\n",
       " 'BIIB': {'@biogen'},\n",
       " 'BLK': {'@BlackRock'},\n",
       " 'BX': {'@blackstone'},\n",
       " 'BA': {'@Boeing'},\n",
       " 'BMY': {'@bmsnews'},\n",
       " 'AVGO': {'@Broadcom'},\n",
       " 'CZR': {'@CaesarsEnt'},\n",
       " 'COF': {'@CapitalOne'},\n",
       " 'CPRI': {'@MichaelKors', '@Versace', '@jimmychoo'},\n",
       " 'CG': {'@OneCarlyle'},\n",
       " 'CCL': {'@CarnivalPLC'},\n",
       " 'CAT': {'@CaterpillarInc'},\n",
       " 'CNC': {'@Centene'},\n",
       " 'CHTR': {'@CharterNewsroom'},\n",
       " 'CC': {'@chemours'},\n",
       " 'CVX': {'@Chevron'},\n",
       " 'CMG': {'@ChipotleTweets'},\n",
       " 'CSCO': {'@Cisco'},\n",
       " 'C': {'@Citi'},\n",
       " 'CLX': {'@Clorox'},\n",
       " 'NET': {'@Cloudflare'},\n",
       " 'KO': {'@CocaCola'},\n",
       " 'COIN': {'@coinbase'},\n",
       " 'CMCSA': {'@comcast'},\n",
       " 'COP': {'@conocophillips'},\n",
       " 'COTY': {'@COTYInc'},\n",
       " 'CRWD': {'@CrowdStrike'},\n",
       " 'CVS': {'@CVSHealth'},\n",
       " 'DE': {'@JohnDeere'},\n",
       " 'DELL': {'@Dell'},\n",
       " 'DAL': {'@Delta'},\n",
       " 'DIS': {'@WaltDisneyCo'},\n",
       " 'D': {'@DominionEnergy'},\n",
       " 'DPZ': {'@dominos'},\n",
       " 'DASH': {'@DoorDash'},\n",
       " 'DOV': {'@DoverCorp'},\n",
       " 'DKNG': {'@DraftKings'},\n",
       " 'DD': {'@DuPont_News'},\n",
       " 'EBAY': {'@eBay'},\n",
       " 'EMR': {'@Emerson_News'},\n",
       " 'ETR': {'@Entergy'},\n",
       " 'EFX': {'@Equifax'},\n",
       " 'DG': {'@DollarGeneral'},\n",
       " 'DLTR': {'@DollarTree'},\n",
       " 'ETSY': {'@Etsy'},\n",
       " 'XOM': {'@exxonmobil'},\n",
       " 'FDX': {'@FedEx'},\n",
       " 'FIS': {'@FISGlobal'},\n",
       " 'FITB': {'@FifthThird'},\n",
       " 'FSLR': {'@FirstSolar'},\n",
       " 'F': {'@Ford'},\n",
       " 'FOX': {'@20thcentury',\n",
       "  '@FOXSports',\n",
       "  '@FOXTV',\n",
       "  '@FoxBusiness',\n",
       "  '@FoxNews',\n",
       "  '@FoxNewsEnt'},\n",
       " 'GME': {'@GameStop'},\n",
       " 'GPS': {'@Gap', '@GapInc'},\n",
       " 'GE': {'@generalelectric'},\n",
       " 'GM': {'@GM'},\n",
       " 'GILD': {'@GileadSciences'},\n",
       " 'GS': {'@GS10KSmallBiz',\n",
       "  '@GS10KWomen',\n",
       "  '@GSCareers',\n",
       "  '@GoldmanSachs',\n",
       "  '@gsdeveloper'},\n",
       " 'HOG': {'@harleydavidson'},\n",
       " 'HAS': {'@Hasbro'},\n",
       " 'HSY': {'@HersheyCompany'},\n",
       " 'HTZ': {'@Hertz'},\n",
       " 'HPE': {'@HPE'},\n",
       " 'HLT': {'@ConradHotels',\n",
       "  '@CurioCollection',\n",
       "  '@EmbassySuites',\n",
       "  '@HamptonByHilton',\n",
       "  '@HiltonGrandVac',\n",
       "  '@HiltonHotels',\n",
       "  '@HiltonNewsroom',\n",
       "  '@Home2Suites',\n",
       "  '@HomewoodSuites',\n",
       "  '@TapestryHilton',\n",
       "  '@TrubyHilton',\n",
       "  '@WaldorfAstoria'},\n",
       " 'HD': {'@HomeDepot'},\n",
       " 'HON': {'@honeywell'},\n",
       " 'HPQ': {'@HP'},\n",
       " 'HUM': {'@Humana'},\n",
       " 'HUN': {'@Huntsman_Corp'},\n",
       " 'IAA': {'@IAA_Auctions'},\n",
       " 'IDA': {'@idahopower'},\n",
       " 'INTC': {'@intel'},\n",
       " 'HCA': {'@HCAhealthcare'},\n",
       " 'INTU': {'@Intuit'},\n",
       " 'ITT': {'@ITT_Inc'},\n",
       " 'JBLU': {'@JetBlue'},\n",
       " 'JNJ': {'@JNJNews'},\n",
       " 'JPM': {'@Chase', '@jpmorgan'},\n",
       " 'K': {'@KelloggCompany'},\n",
       " 'KKR': {'@KKR_Co'},\n",
       " 'KSS': {'@Kohls'},\n",
       " 'KHC': {'@KraftHeinzCo'},\n",
       " 'KR': {'@KrogerNews', '@kroger'},\n",
       " 'IBM': {'@IBM'},\n",
       " 'EL': {'@BobbiBrown',\n",
       "  '@Clinique',\n",
       "  '@DrJartUS',\n",
       "  '@EsteeLauder',\n",
       "  '@JoMaloneLondon',\n",
       "  '@MACcosmetics',\n",
       "  '@aveda'},\n",
       " 'LAZ': {'@Lazard'},\n",
       " 'LLY': {'@LillyPad'},\n",
       " 'LYV': {'@LiveNation'},\n",
       " 'LMT': {'@LockheedMartin'},\n",
       " 'L': {'@Loews_Hotels'},\n",
       " 'LPX': {'@lpcorp'},\n",
       " 'LOW': {'@Lowes'},\n",
       " 'LCID': {'@LucidMotors'},\n",
       " 'LULU': {'@lululemon'},\n",
       " 'LYFT': {'@lyft'},\n",
       " 'M': {'@macysnews'},\n",
       " 'MA': {'@MastercardNews'},\n",
       " 'MAT': {'@Mattel'},\n",
       " 'MCD': {'@McDonaldsCorp'},\n",
       " 'MRK': {'@Merck'},\n",
       " 'META': {'@Meta', '@facebook'},\n",
       " 'MGM': {'@MGMResortsIntl'},\n",
       " 'MSFT': {'@Microsoft'},\n",
       " 'MRNA': {'@moderna_tx'},\n",
       " 'TAP': {'@MolsonCoors'},\n",
       " 'MCO': {'@MoodysInvSvc'},\n",
       " 'MS': {'@MorganStanley'},\n",
       " 'MAR': {'@MarriottBonvoy'},\n",
       " 'NFLX': {'@netflix'},\n",
       " 'NYT': {'@nytimes'},\n",
       " 'NWS': {'@DowJones',\n",
       "  '@HarperCollins',\n",
       "  '@REA_Group',\n",
       "  '@Storyful',\n",
       "  '@nypost',\n",
       "  '@realtordotcom'},\n",
       " 'NKE': {'@Nike'},\n",
       " 'JWN': {'@Nordstrom'},\n",
       " 'NCLH': {'@CruiseNorwegian'},\n",
       " 'NVAX': {'@Novavax'},\n",
       " 'NVDA': {'@nvidia'},\n",
       " 'NDAQ': {'@Nasdaq'},\n",
       " 'OMC': {'@Omnicom'},\n",
       " 'ORCL': {'@Oracle'},\n",
       " 'PLTR': {'@PalantirTech'},\n",
       " 'PARAA': {'@paramountco'},\n",
       " 'PYPL': {'@PayPal'},\n",
       " 'PTON': {'@onepeloton'},\n",
       " 'PEP': {'@PepsiCo'},\n",
       " 'PFE': {'@pfizer'},\n",
       " 'PCG': {'@PGE4Me'},\n",
       " 'OXY': {'@WeAreOxy'},\n",
       " 'PNC': {'@PNCBank'},\n",
       " 'PG': {'@ProcterGamble'},\n",
       " 'QCOM': {'@Qualcomm'},\n",
       " 'RL': {'@RalphLauren'},\n",
       " 'RTX': {'@RaytheonTech'},\n",
       " 'REGN': {'@Regeneron'},\n",
       " 'PM': {'@InsidePMI'},\n",
       " 'PSX': {'@Phillips66Co'},\n",
       " 'PINS': {'@Pinterest'},\n",
       " 'RIVN': {'@Rivian'},\n",
       " 'HOOD': {'@RobinhoodApp'},\n",
       " 'RBLX': {'@Roblox'},\n",
       " 'ROKU': {'@Roku'},\n",
       " 'RCL': {'@NewsfromRCgroup'},\n",
       " 'SPGI': {'@SPGlobal'},\n",
       " 'CRM': {'@salesforce'},\n",
       " 'SBAC': {'@sbasite'},\n",
       " 'SCHW': {'@CharlesSchwab'},\n",
       " 'SRE': {'@sempra'},\n",
       " 'LUV': {'@SouthwestAir'},\n",
       " 'SPOT': {'@Spotify'},\n",
       " 'SBUX': {'@Starbucks'},\n",
       " 'STT': {'@StateStreet'},\n",
       " 'RUN': {'@Sunrun'},\n",
       " 'SPG': {'@ShopSimon'},\n",
       " 'SIRI': {'@SIRIUSXM'},\n",
       " 'SKX': {'@SKECHERSUSA'},\n",
       " 'TSLA': {'@Tesla'},\n",
       " 'TMO': {'@thermofisher'},\n",
       " 'TRU': {'@TransUnion'},\n",
       " 'TRIP': {'@Tripadvisor'},\n",
       " 'TSN': {'@TysonFoods'},\n",
       " 'UBER': {'@Uber'},\n",
       " 'TMUS': {'@TMobile'},\n",
       " 'UPS': {'@UPS'},\n",
       " 'X': {'@U_S_Steel'},\n",
       " 'UNH': {'@UnitedHealthGrp'},\n",
       " 'USFD': {'@USFoods'},\n",
       " 'MTN': {'@VailResorts'},\n",
       " 'VZ': {'@Verizon'},\n",
       " 'VTRS': {'@ViatrisInc'},\n",
       " 'VSCO': {'@VictoriasSecret'},\n",
       " 'V': {'@Visa'},\n",
       " 'VMW': {'@VMware'},\n",
       " 'VOYA': {'@Voya'},\n",
       " 'UA': {'@UnderArmour'},\n",
       " 'UAL': {'@united'},\n",
       " 'WFC': {'@WellsFargo'},\n",
       " 'WEN': {'@Wendys'},\n",
       " 'WE': {'@WeWork'},\n",
       " 'WTW': {'@WTWcorporate'},\n",
       " 'WWD': {'@woodward_inc'},\n",
       " 'WWE': {'@WWE'},\n",
       " 'ZG': {'@ZillowGroup'},\n",
       " 'WBA': {'@WBA_Global'},\n",
       " 'WMT': {'@Walmart'},\n",
       " 'WBD': {'@wbd'},\n",
       " 'W': {'@Wayfair'},\n",
       " 'ZM': {'@Zoom'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#연구대상 기업 티커, 트위터 계정 확인\n",
    "print(len(dic_n))\n",
    "dic_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ce98421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #트위터 데이터 파일 가져오는 경로\n",
    "# file_path = '/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/01. Raw Data'\n",
    "# #선별된 트위터 데이터 파일 저장할 경로\n",
    "# save_path = '/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/02. Selected Data'\n",
    "\n",
    "# for key in tqdm(dic_n.keys()):\n",
    "#     try:\n",
    "#         if len(dic_n[key]) == 1:\n",
    "#             df = pd.read_csv(file_path + '/' + list(dic_n[key])[0] + '.csv', index_col = 0, lineterminator='\\n', low_memory = False)\n",
    "#             df.to_csv(save_path + '/' + key + '.csv')\n",
    "#         else:\n",
    "#             df = pd.DataFrame(columns = ['datetime','content','username'] )\n",
    "#             for i in range(len(dic_n[key])):\n",
    "#                 temp = pd.read_csv(file_path + '/' + list(dic_n[key])[i] + '.csv', index_col = 0, lineterminator='\\n', low_memory = False)\n",
    "#                 df = pd.concat([df, temp], axis = 0)\n",
    "#             df.sort_values(by = 'datetime', inplace = True)\n",
    "#             df.reset_index(inplace = True, drop = True)\n",
    "#             df.to_csv(save_path + '/' + key + '.csv')\n",
    "#     except Exception as e:\n",
    "#         print(key)\n",
    "#         print(dic_n[key])\n",
    "#         print(e)\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a00130b",
   "metadata": {},
   "source": [
    "# 3. 계정이 제대로 멘션되지 않은 트윗 삭제 & 언론, 투자기관, 자체 홍보 USER ID 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6b0f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#제거해야 할 user id 파일 불러오기\n",
    "ids = pd.read_excel('/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/01. 메타 데이터/Financials&Media_user_ids_v0.1.xlsx', sheet_name = 'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2006205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user id들 집합으로 만들기\n",
    "ids = set(ids['Accounts'])\n",
    "ids_n = set()\n",
    "for i in ids:\n",
    "    i = i[1:]\n",
    "    ids_n.add(i)\n",
    "#분석 대상 기업 티커 불러오기\n",
    "companies = os.listdir('/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/02. Selected Data')\n",
    "#companies.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ef2d2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EvercoreISI', 'Amrock', 'cnbc', 'keybank', 'wsj', 'KemperInsurance', 'Deseret', 'guardian', 'sacbee_news', 'MorganStanley', 'Tradeweb', 'FirstHorizonBnk', 'cbcnews', 'nytimes', 'coinbase', 'USATODAY', 'ocregister', 'EquitableFin', 'ajc', 'ComericaBank', 'umpquabank', 'FrostBank', 'Ally', 'LPL', 'Stifel', 'principal', 'aflac', 'abc', 'Discover', 'reviewjournal', 'WebsterBank', 'lincolnfingroup', 'csmonitor', 'PioneerPress', 'Prudential', 'PhillyInquirer', 'Nasdaq', 'france24_en', 'firstcitizens', 'GSCareers', 'WellsFargo', 'MGIC', 'AmegyBank', 'EverestIns', 'BOKFinancial', 'statesman', 'LasVegasSun', 'TheHartford', 'time', 'TucsonStar', 'Rock_Conn', 'FTI_Global', 'BankofAmerica', 'B_BInsurance', 'MoodysInvSvc', 'GoldmanSachs', 'Jefferies', 'BlueOwlCapital', 'AIGinsurance', 'FHBHawaii', 'latimes', 'Voya', 'MetLife', 'chicagotribune', 'Assurant', 'AskUnum', 'CBS', 'stltoday', 'ares_management', 'GS10KWomen', 'OneCarlyle', 'sltrib', 'telegraph', 'FactSet', 'cnn', 'ZionsBank', 'firstrepublic', 'bbcworld', 'TruistNews', 'thehill', 'NBCNews', 'MSCI_Inc', 'Primerica', 'Chase', 'skynewsbreak', 'thirdfederal', 'VirtuFinancial', 'NexsysTech', 'OneMain', 'erie_insurance', 'StarTribune', 'baltimoresun', 'Lazard', 'ap', 'ExaminerOnline', 'BankOZK', 'calbanktrust', 'CBOE', 'blackstone', 'MorningstarInc', 'MarkelStyle', 'skynews', 'NevadaStateBank', 'independent', 'newsobserver', 'Travelers', 'THR', 'Suntimes', 'Ryan_Specialty', 'TheOnion', 'Wintrust', 'PB_USA', 'FifthThird', 'Upstart', 'Allstate', 'breakingnews', 'ChubbNA', 'nbarizona', 'progressive', 'DispatchAlerts', 'ICE_Markets', 'RobinhoodApp', 'IBKR', 'PNCBank', 'ameriprise', 'CapitalOne', 'rt_com', 'denverpost', 'reuters', 'RocketAuto', 'AmericanExpress', 'xhnews', 'huffpost', 'synovus', 'seattletimes', 'MarketAxess', 'Loews_Hotels', 'MarshMcLennan', 'freep', 'WAllianceBank', 'RegionsBank', 'jpmorgan', 'SallieMae', 'RocketPressRoom', 'gsdeveloper', 'CharlesSchwab', 'Citi', 'dallasnews', 'PNFP', 'MiamiHerald', 'SPGlobal', 'CitizensBank', 'assuredguaranty', 'AXIS_Capital', 'SoFi', 'TRowePrice', 'GS10KSmallBiz', 'PBS', 'BlackRock', 'seattlepi', 'WashTimes', 'HoustonChron', 'PittsburghPG', 'SunSentinel', 'UWMlending', 'washingtonpost', 'VectraBank', 'WRBerkleyCorp', 'EastWestBank', 'BNYMellon', 'ladailynews', 'GlobeLife', 'MandT_Bank', 'orlandosentinel', 'RaymondJames', 'usbank', 'hartfordcourant', 'ajenglish', 'KCStar', 'OANN', 'synchrony', 'journalsentinel', 'InvescoUS', 'RGA_RE', 'SEIInvestments', 'StateStreet', 'The_Hanover', 'newsweek', 'KKR_Co', 'NorthernTrust', 'SVB_Financial', 'popular', 'RocketMortgage', 'indystar', 'Everest_Re', 'RocketLoans', 'Newsday', 'CMEGroup', 'IndianExpress', 'BankofHawaii', 'guardiannews', 'cnnbrk', 'Aon_plc', 'GallagherGlobal', 'mcall', 'bbcbreaking', 'BrighthouseFin', 'bostonherald', 'ndtv', 'Huntington_Bank', 'mercnews', 'WTWcorporate', 'FirstAmNews', 'ThePlainDealer', 'nypost', 'RTDNEWS', 'CNA_Insurance', 'financialtimes', 'CommerceBank', 'theeconomist', 'CoreDigitalJobs'}\n",
      "['CSCO.csv', 'UAL.csv', 'W.csv', 'BA.csv', 'GILD.csv', 'ZG.csv', 'HUN.csv', 'V.csv', 'FOX.csv', 'MO.csv', 'LAZ.csv', 'CHTR.csv', 'BBY.csv', 'WBA.csv', 'HCA.csv', 'AN.csv', 'C.csv', 'T.csv', 'MGM.csv', 'HUM.csv', 'CG.csv', 'BAC.csv', 'PSX.csv', 'WWE.csv', 'LYFT.csv', 'WBD.csv', 'CC.csv', 'F.csv', 'HOG.csv', 'ADBE.csv', 'HTZ.csv', 'TSN.csv', 'PEP.csv', 'IDA.csv', 'LLY.csv', 'WWD.csv', 'NWS.csv', 'LOW.csv', 'WE.csv', 'JBLU.csv', 'DBX.csv', 'D.csv', 'MRK.csv', 'COIN.csv', 'KHC.csv', 'ABNB.csv', 'UNP.csv', 'ABBV.csv', 'NVAX.csv', 'ORCL.csv', 'USFD.csv', 'ETR.csv', 'EBAY.csv', 'GME.csv', 'SBUX.csv', 'INTU.csv', 'DPZ.csv', 'AMC.csv', 'PG.csv', 'CAT.csv', 'MCD.csv', 'AMZN.csv', 'ACI.csv', 'INTC.csv', 'GM.csv', 'TMO.csv', 'OXY.csv', 'RL.csv', 'MMM.csv', 'AFRM.csv', 'HSY.csv', 'MTN.csv', 'KO.csv', 'PYPL.csv', 'RUN.csv', 'UPS.csv', 'EMR.csv', 'MSFT.csv', 'UBER.csv', 'DD.csv', 'ACN.csv', 'CMG.csv', 'HPQ.csv', 'CCL.csv', 'AVY.csv', 'DKNG.csv', 'ATVI.csv', 'DE.csv', 'PARAA.csv', 'SPG.csv', 'NDAQ.csv', 'RTX.csv', 'PNC.csv', 'PINS.csv', 'BIIB.csv', 'NVDA.csv', 'HD.csv', 'AON.csv', 'FDX.csv', 'DG.csv', 'HIG.csv', 'SKX.csv', 'SCHW.csv', 'AXP.csv', 'HPE.csv', 'XOM.csv', 'HOOD.csv', 'CVX.csv', 'CMCSA.csv', 'PCG.csv', 'NET.csv', 'TRIP.csv', 'SBAC.csv', 'SIRI.csv', 'NKE.csv', 'FIS.csv', 'ETSY.csv', 'TAP.csv', 'MAR.csv', 'KR.csv', 'IBM.csv', 'IAA.csv', 'VSCO.csv', 'SPGI.csv', 'LULU.csv', 'WFC.csv', 'EL.csv', 'GS.csv', 'SOFI.csv', 'PM.csv', 'MCO.csv', 'CLX.csv', 'DELL.csv', 'DIS.csv', 'GE.csv', 'LPX.csv', 'WEN.csv', 'ETN.csv', 'ITT.csv', 'NFLX.csv', 'FITB.csv', 'FIVN.csv', 'AXON.csv', 'CVS.csv', 'JPM.csv', 'PTON.csv', 'ABT.csv', 'OMC.csv', 'COF.csv', 'MRNA.csv', 'TSLA.csv', 'COP.csv', 'MAT.csv', 'CNC.csv', 'VMW.csv', 'RIVN.csv', 'VTRS.csv', 'ALSN.csv', 'ALK.csv', 'META.csv', 'AAL.csv', 'CNA.csv', 'CZR.csv', 'LCID.csv', 'CRWD.csv', 'SRE.csv', 'RCL.csv', 'COTY.csv', 'GOOG.csv', 'NYT.csv', 'LYV.csv', 'KSS.csv', 'PFE.csv', 'AVGO.csv', 'REGN.csv', 'RBLX.csv', 'UA.csv', 'VZ.csv', 'FSLR.csv', 'STT.csv', 'SPOT.csv', 'GPS.csv', 'QCOM.csv', 'DASH.csv', 'LUV.csv', 'MS.csv', 'BK.csv', 'ZM.csv', 'DAL.csv', 'K.csv', 'JWN.csv', 'NCLH.csv', 'UNH.csv', 'PLTR.csv', 'WTW.csv', 'VOYA.csv', 'MA.csv', 'TRU.csv', 'HON.csv', 'X.csv', 'AAPL.csv', 'BX.csv', 'HLT.csv', 'DLTR.csv', 'HAS.csv', 'TMUS.csv', 'WMT.csv', 'LMT.csv', 'KKR.csv', 'BMY.csv', 'EFX.csv', 'SPLK.csv', 'L.csv', 'CPRI.csv', 'JNJ.csv', 'DOV.csv', 'M.csv', 'CRM.csv', 'BLK.csv', 'ROKU.csv']\n"
     ]
    }
   ],
   "source": [
    "#제거해야할 user id 집합 확인\n",
    "print(ids_n)\n",
    "#분석 대상 기업 티커 리스트 확인\n",
    "print(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95206fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#계정이 제대로 멘션되지 않은 트윗 삭제하는 함수\n",
    "def content_check(content, accounts):\n",
    "    for account in accounts:\n",
    "        if account.lower() in str(content).lower(): return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "699e983e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "\n",
    "# file_path = '/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/02. Selected Data'\n",
    "# save_path = '/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/03. Selected Data'\n",
    "\n",
    "# for company in companies:\n",
    "#     try:\n",
    "#         #제거해야할 id 갱신 (언론, 투자기관)\n",
    "#         ids_n = set()\n",
    "#         for i in ids:\n",
    "#             i = i[1:]\n",
    "#             ids_n.add(i)\n",
    "#         #자체 홍보 id 추가\n",
    "#         accounts = dic_n[company[:-4]]\n",
    "#         for account in accounts:\n",
    "#             account = account[1:]\n",
    "#             ids_n.add(account)\n",
    "#         print(company)\n",
    "#         #파일 불러오기\n",
    "#         df = pd.read_csv(file_path + '/' + company, lineterminator = '\\n', index_col = 0)\n",
    "#         #계정이 제대로 멘션되지 않은 경우 삭제\n",
    "#         df = df[df['content'].progress_apply(lambda x: content_check(x, accounts))]\n",
    "#         #언론, 투자기관, 자체 홍보 트윗 삭제\n",
    "#         df = df[~(df.isin(ids_n)['username'])]\n",
    "#         df = df[['datetime', 'content', 'username']]\n",
    "#         df.astype({'datetime' : 'datetime64'})\n",
    "#         df.sort_values(by = 'datetime', inplace = True)\n",
    "#         df.reset_index(drop = True, inplace = True)\n",
    "#         df.to_csv(save_path + '/' + company)\n",
    "#         #메모리 공간 확보를 위해 변수 삭제\n",
    "#         del df\n",
    "#         del ids_n\n",
    "#         del accounts\n",
    "#     except Exception as e:\n",
    "#         print('Error' + company)\n",
    "#         print(e)\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d95570ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "file_path = '/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/02. Selected Data'\n",
    "save_path = '/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/03. Selected Data'\n",
    "\n",
    "remove = os.listdir('/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/03. Selected Data')\n",
    "remove.remove('.DS_Store')\n",
    "for r in remove:\n",
    "    companies.remove(r)\n",
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ee120a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOG.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 160617/160617 [00:00<00:00, 1133667.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 305829/305829 [00:00<00:00, 1169616.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINS.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1066828/1066828 [00:00<00:00, 1197832.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 255211/255211 [00:00<00:00, 1173232.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLX.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 60049/60049 [00:00<00:00, 1046349.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMUS.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 2680950/2680950 [00:02<00:00, 1284859.68it/s]\n"
     ]
    }
   ],
   "source": [
    "for company in companies:\n",
    "    try:\n",
    "        #제거해야할 id 갱신 (언론, 투자기관)\n",
    "        ids_n = set()\n",
    "        for i in ids:\n",
    "            i = i[1:] + '\\r'\n",
    "            ids_n.add(i)\n",
    "        #자체 홍보 id 추가\n",
    "        accounts = dic_n[company[:-4]]\n",
    "        for account in accounts:\n",
    "            account = account[1:] + '\\r'\n",
    "            ids_n.add(account)\n",
    "        print(company)\n",
    "        #파일 불러오기\n",
    "        df = pd.read_csv(file_path + '/' + company, lineterminator = '\\n', index_col = 0)\n",
    "        #계정이 제대로 멘션되지 않은 경우 삭제\n",
    "        df = df[df['content'].progress_apply(lambda x: content_check(x, accounts))]\n",
    "        #언론, 투자기관, 자체 홍보 트윗 삭제\n",
    "        df = df[~(df.isin(ids_n)['username\\r'])]\n",
    "        df = df[['datetime', 'content', 'username\\r']]\n",
    "        df.astype({'datetime' : 'datetime64'})\n",
    "        df.sort_values(by = 'datetime', inplace = True)\n",
    "        df.reset_index(drop = True, inplace = True)\n",
    "        df.to_csv(save_path + '/' + company)\n",
    "        #메모리 공간 확보를 위해 변수 삭제\n",
    "        del df\n",
    "        del ids_n\n",
    "        del accounts\n",
    "    except Exception as e:\n",
    "        print('Error: ' + company)\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d515d04",
   "metadata": {},
   "source": [
    "# 4. BERT로 트위터 감성분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c841df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['HOG.csv', 'GM.csv', 'PINS.csv', 'NVDA.csv', 'CLX.csv', 'TMUS.csv']\n",
    "for company in companies :\n",
    "    df = pd.read_csv(save_path + '/' + company, lineterminator = '\\n', index_col = 0)\n",
    "    df['username'] = df['username\\r'].apply(lambda x: x[:-1])\n",
    "    df = df[['datetime', 'content', 'username']]\n",
    "    df.to_csv(save_path + '/' + company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "496a76dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>content</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 07:04:01+00:00</td>\n",
       "      <td>@Clorox love all of your products!</td>\n",
       "      <td>AshleyH65559795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 12:11:52+00:00</td>\n",
       "      <td>@KhaleesiMarieJ @Clorox hit her with that expr...</td>\n",
       "      <td>Reedzthewise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 15:33:33+00:00</td>\n",
       "      <td>I applied to host a Scentiva™ Paradise Party! ...</td>\n",
       "      <td>omegano83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 17:25:21+00:00</td>\n",
       "      <td>Hey @Clorox Happy New Year! I’m cleaning up an...</td>\n",
       "      <td>ace2xbaby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 23:11:19+00:00</td>\n",
       "      <td>@Clorox could someone get in touch plz. Brough...</td>\n",
       "      <td>Donna92273624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44610</th>\n",
       "      <td>2022-10-11 18:23:54+00:00</td>\n",
       "      <td>Gold medalist Allyson Felix shows us what it's...</td>\n",
       "      <td>KetchumPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44611</th>\n",
       "      <td>2022-10-11 19:04:30+00:00</td>\n",
       "      <td>Wow, how is your new wonderful soft @Clorox</td>\n",
       "      <td>yourbrandma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44612</th>\n",
       "      <td>2022-10-11 21:14:11+00:00</td>\n",
       "      <td>@Clorox @ThaBadessst So are you all thinking a...</td>\n",
       "      <td>Katherine_L_R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44613</th>\n",
       "      <td>2022-10-11 21:46:02+00:00</td>\n",
       "      <td>@Clorox @ThaBadessst Do you have comparable item?</td>\n",
       "      <td>Katherine_L_R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44614</th>\n",
       "      <td>2022-10-11 23:17:03+00:00</td>\n",
       "      <td>@Clorox has compostible wipes. @SeventhGen doe...</td>\n",
       "      <td>Tia7510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44615 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        datetime  \\\n",
       "0      2018-01-01 07:04:01+00:00   \n",
       "1      2018-01-01 12:11:52+00:00   \n",
       "2      2018-01-01 15:33:33+00:00   \n",
       "3      2018-01-01 17:25:21+00:00   \n",
       "4      2018-01-01 23:11:19+00:00   \n",
       "...                          ...   \n",
       "44610  2022-10-11 18:23:54+00:00   \n",
       "44611  2022-10-11 19:04:30+00:00   \n",
       "44612  2022-10-11 21:14:11+00:00   \n",
       "44613  2022-10-11 21:46:02+00:00   \n",
       "44614  2022-10-11 23:17:03+00:00   \n",
       "\n",
       "                                                 content         username  \n",
       "0                     @Clorox love all of your products!  AshleyH65559795  \n",
       "1      @KhaleesiMarieJ @Clorox hit her with that expr...     Reedzthewise  \n",
       "2      I applied to host a Scentiva™ Paradise Party! ...        omegano83  \n",
       "3      Hey @Clorox Happy New Year! I’m cleaning up an...        ace2xbaby  \n",
       "4      @Clorox could someone get in touch plz. Brough...    Donna92273624  \n",
       "...                                                  ...              ...  \n",
       "44610  Gold medalist Allyson Felix shows us what it's...        KetchumPR  \n",
       "44611        Wow, how is your new wonderful soft @Clorox      yourbrandma  \n",
       "44612  @Clorox @ThaBadessst So are you all thinking a...    Katherine_L_R  \n",
       "44613  @Clorox @ThaBadessst Do you have comparable item?    Katherine_L_R  \n",
       "44614  @Clorox has compostible wipes. @SeventhGen doe...          Tia7510  \n",
       "\n",
       "[44615 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(save_path + '/CLX.csv' , lineterminator = '\\n', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26567019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
