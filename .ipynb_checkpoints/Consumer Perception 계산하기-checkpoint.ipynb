{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d301ba9f",
   "metadata": {},
   "source": [
    "# Consumer Perception 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5db7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d642d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/06. 회귀분석 데이터/Composed_Data_ver1.1.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07648400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = os.listdir('/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/02. Selected Data')\n",
    "companies.remove('.DS_Store')\n",
    "len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef167e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_df['Positive Consumer Perception'] = 0\n",
    "news_df['Negative Consumer Perception'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc97c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_path = '/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/02. Selected Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a06d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████▌                   | 110/220 [29:00<3:01:01, 98.74s/it]"
     ]
    }
   ],
   "source": [
    "total = pd.DataFrame()\n",
    "for company in tqdm(companies):\n",
    "    df = pd.read_csv(twitter_path + '/' + company, lineterminator = '\\n')\n",
    "    total = pd.concat([total, df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50803e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = total\n",
    "twitter_df['datetime'] = twitter_df['datetime'].apply(lambda x : x[:-15])\n",
    "\n",
    "for i in tqdm(range(len(news_df))):\n",
    "    try:\n",
    "        ticker = news_df.loc[i, 'Ticker'][2:-2]\n",
    "        publish_date = news_df.loc[i, 'Publish Date']\n",
    "        #news publish date와 일치하는 트위터 게시일이 있는 경우\n",
    "        if publish_date in list(twitter_df['datetime']):\n",
    "            cp_pos = 0\n",
    "            cp_neg = 0\n",
    "            average_pos = 0\n",
    "            average_neg = 0\n",
    "            for j in range(15):\n",
    "                #15일간의 Positive 확률의 평균값 구하기\n",
    "                calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = j)).strftime(\"%Y-%m-%d\")\n",
    "                pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "                neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "                cp_pos += pos_sentiment\n",
    "                cp_neg += neg_sentiment\n",
    "            for j in range(100):\n",
    "                calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = -30 - j)).strftime(\"%Y-%m-%d\")\n",
    "                pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "                neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "                average_pos += pos_sentiment\n",
    "                average_neg += neg_sentiment\n",
    "            cp_pos /= 15\n",
    "            cp_neg /= 15\n",
    "            average_pos /= 100\n",
    "            average_neg /= 100\n",
    "            cp_pos = cp_pos - average_pos\n",
    "            cp_neg = cp_neg - average_neg\n",
    "        #news publish date와 일치하는 트위터 게시일이 없는 경우\n",
    "        else:\n",
    "            publish_datetime = datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10]))\n",
    "            for k in range(30):\n",
    "                if (publish_datetime + timedelta(days = k)).strftime(\"%Y-%m-%d\") in list(twitter_df['datetime']):\n",
    "                    publish_date = (publish_datetime + timedelta(days = k)).strftime(\"%Y-%m-%d\")\n",
    "                    break\n",
    "            cp_pos = 0\n",
    "            cp_neg = 0\n",
    "            for j in range(1000):\n",
    "                #15일간의 Positive 확률의 평균값 구하기\n",
    "                calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = j)).strftime(\"%Y-%m-%d\")\n",
    "                pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "                neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "                cp_pos += pos_sentiment\n",
    "                cp_neg += neg_sentiment\n",
    "            for j in range(100):\n",
    "                calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = -30 - j)).strftime(\"%Y-%m-%d\")\n",
    "                pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "                neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "                average_pos += pos_sentiment\n",
    "                average_neg += neg_sentiment\n",
    "            cp_pos /= 15\n",
    "            cp_neg /= 15\n",
    "            average_pos /= 100\n",
    "            average_neg /= 100\n",
    "            cp_pos = cp_pos - average_pos\n",
    "            cp_neg = cp_neg - average_neg\n",
    "        news_df.iloc[i,-1] = cp_neg\n",
    "        news_df.iloc[i,-2] = cp_pos\n",
    "                \n",
    "    except Exception as e :\n",
    "        print(ticker, publish_date)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "273bfbd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 5/4561 [00:15<3:15:34,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL 2019-01-03\n",
      "'negative'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                        | 6/4561 [00:21<4:37:04,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFLX 2019-01-06\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 7/4561 [00:22<4:07:54,  3.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m calculation_date \u001b[38;5;241m=\u001b[39m (datetime(\u001b[38;5;28mint\u001b[39m(publish_date[:\u001b[38;5;241m4\u001b[39m]), \u001b[38;5;28mint\u001b[39m(publish_date[\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m7\u001b[39m]), \u001b[38;5;28mint\u001b[39m(publish_date[\u001b[38;5;241m8\u001b[39m:\u001b[38;5;241m10\u001b[39m])) \u001b[38;5;241m+\u001b[39m timedelta(days \u001b[38;5;241m=\u001b[39m j))\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m pos_sentiment \u001b[38;5;241m=\u001b[39m twitter_df[twitter_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m calculation_date][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 23\u001b[0m neg_sentiment \u001b[38;5;241m=\u001b[39m twitter_df[\u001b[43mtwitter_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcalculation_date\u001b[49m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     24\u001b[0m cp_pos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pos_sentiment\n\u001b[1;32m     25\u001b[0m cp_neg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m neg_sentiment\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:5623\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5620\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 5623\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:283\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:73\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(news_df))):\n",
    "    try:\n",
    "        ticker = news_df.loc[i, 'Ticker'][2:-2]\n",
    "        publish_date = news_df.loc[i, 'Publish Date']\n",
    "        #트위터 데이터에서 필요 정보 가져오기\n",
    "        twitter_df = pd.read_csv(twitter_path + '/' + ticker + '.csv', lineterminator = '\\n')\n",
    "#         for i in range(len(twitter_df)):\n",
    "#             try:\n",
    "#                 twitter_df.iloc[i,1] = twitter_df.iloc[i,1][:-15]\n",
    "#             except:\n",
    "#                 pass\n",
    "        twitter_df['datetime'] = twitter_df['datetime'].apply(lambda x : x[:-15])\n",
    "        #news publish date와 일치하는 트위터 게시일이 있는 경우\n",
    "        if publish_date in list(twitter_df['datetime']):\n",
    "            cp_pos = 0\n",
    "            cp_neg = 0\n",
    "            average_pos = 0\n",
    "            average_neg = 0\n",
    "            for j in range(15):\n",
    "                #15일간의 Positive 확률의 평균값 구하기\n",
    "                calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = j)).strftime(\"%Y-%m-%d\")\n",
    "                pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "                neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "                cp_pos += pos_sentiment\n",
    "                cp_neg += neg_sentiment\n",
    "            for j in range(100):\n",
    "                calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = -30 - j)).strftime(\"%Y-%m-%d\")\n",
    "                pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "                neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "                average_pos += pos_sentiment\n",
    "                average_neg += neg_sentiment\n",
    "            cp_pos /= 15\n",
    "            cp_neg /= 15\n",
    "            average_pos /= 100\n",
    "            average_neg /= 100\n",
    "            cp_pos = cp_pos - average_pos\n",
    "            cp_neg = cp_neg - average_neg\n",
    "        #news publish date와 일치하는 트위터 게시일이 없는 경우\n",
    "        else:\n",
    "            publish_datetime = datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10]))\n",
    "            for k in range(30):\n",
    "                if (publish_datetime + timedelta(days = k)).strftime(\"%Y-%m-%d\") in list(twitter_df['datetime']):\n",
    "                    publish_date = (publish_datetime + timedelta(days = k)).strftime(\"%Y-%m-%d\")\n",
    "                    break\n",
    "            cp_pos = 0\n",
    "            cp_neg = 0\n",
    "            for j in range(1000):\n",
    "                #15일간의 Positive 확률의 평균값 구하기\n",
    "                calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = j)).strftime(\"%Y-%m-%d\")\n",
    "                pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "                neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "                cp_pos += pos_sentiment\n",
    "                cp_neg += neg_sentiment\n",
    "            for j in range(100):\n",
    "                calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = -30 - j)).strftime(\"%Y-%m-%d\")\n",
    "                pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "                neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "                average_pos += pos_sentiment\n",
    "                average_neg += neg_sentiment\n",
    "            cp_pos /= 15\n",
    "            cp_neg /= 15\n",
    "            average_pos /= 100\n",
    "            average_neg /= 100\n",
    "            cp_pos = cp_pos - average_pos\n",
    "            cp_neg = cp_neg - average_neg\n",
    "        news_df.iloc[i,-1] = cp_neg\n",
    "        news_df.iloc[i,-2] = cp_pos\n",
    "                \n",
    "    except Exception as e :\n",
    "        print(ticker, publish_date)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a6342a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Publish Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Main Text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Description</th>\n",
       "      <th>News Type</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Date Comparison</th>\n",
       "      <th>Investor Reaction</th>\n",
       "      <th>Positive Consumer Perception</th>\n",
       "      <th>Negative Consumer Perception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.nytimes.com/2019/01/01/business/me...</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Netflix Blocks Show in Saudi Arabia Critical o...</td>\n",
       "      <td>Netflix has blocked an episode of its show “Pa...</td>\n",
       "      <td>['NFLX']</td>\n",
       "      <td>['Netflix Inc']</td>\n",
       "      <td>ESG</td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>0.064605</td>\n",
       "      <td>-0.025613</td>\n",
       "      <td>0.019053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.nytimes.com/2019/01/02/business/ju...</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>Julie Sweet of Accenture Could See Her Future....</td>\n",
       "      <td>Why did you go to law school?\\n \\n I decided t...</td>\n",
       "      <td>['ACN']</td>\n",
       "      <td>['Accenture Plc Class A']</td>\n",
       "      <td>Non-ESG</td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.025522</td>\n",
       "      <td>0.007074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.nytimes.com/2019/01/02/business/te...</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>Tesla Reports Record Output, but Cuts Prices, ...</td>\n",
       "      <td>Tesla shares ended trading nearly 7 percent lo...</td>\n",
       "      <td>['TSLA']</td>\n",
       "      <td>['Tesla Inc']</td>\n",
       "      <td>Financial Performance</td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.004269</td>\n",
       "      <td>-0.009292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.nytimes.com/2019/01/03/business/de...</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>Bristol-Myers to Acquire Celgene in Deal Worth...</td>\n",
       "      <td>Bristol-Myers Squibb said on Thursday that it ...</td>\n",
       "      <td>['BMY']</td>\n",
       "      <td>['Bristol Myers Squibb']</td>\n",
       "      <td>Financial Performance</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.059849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.nytimes.com/2019/01/03/business/de...</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>Was Apple’s Warning a Surprise? Not to Its Sup...</td>\n",
       "      <td>Apple’s stock fell 10 percent on Thursday, its...</td>\n",
       "      <td>['AAPL']</td>\n",
       "      <td>['Apple Inc']</td>\n",
       "      <td>Financial Performance</td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.027306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>https://www.nytimes.com/2022/10/18/technology/...</td>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>Amazon Labor Union Loses Election at Warehouse...</td>\n",
       "      <td>Mr. Smalls said the election “wasn’t free and ...</td>\n",
       "      <td>['AMZN']</td>\n",
       "      <td>['Amazon.Com Inc.']</td>\n",
       "      <td>ESG</td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>https://www.nytimes.com/2022/10/20/technology/...</td>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>Texas Sues Google for Collecting Biometric Dat...</td>\n",
       "      <td>José Castañeda, a Google spokesman, said in a ...</td>\n",
       "      <td>['GOOG']</td>\n",
       "      <td>['Alphabet Inc Class C']</td>\n",
       "      <td>ESG</td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.040082</td>\n",
       "      <td>0.032693</td>\n",
       "      <td>-0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>https://www.nytimes.com/2022/10/25/technology/...</td>\n",
       "      <td>2022-10-25</td>\n",
       "      <td>Microsoft Reports Slowest Revenue Growth in Fi...</td>\n",
       "      <td>In the most recent quarter, softness in the gl...</td>\n",
       "      <td>['MSFT']</td>\n",
       "      <td>['Microsoft Corp']</td>\n",
       "      <td>Financial Performance</td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.036752</td>\n",
       "      <td>-0.036672</td>\n",
       "      <td>0.025153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>https://www.nytimes.com/2022/10/27/technology/...</td>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>Apple’s iPhone Powers Growth, but Signs Point ...</td>\n",
       "      <td>When Apple released the 16th version of its iP...</td>\n",
       "      <td>['AAPL']</td>\n",
       "      <td>['Apple Inc']</td>\n",
       "      <td>Financial Performance</td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.003742</td>\n",
       "      <td>-0.036672</td>\n",
       "      <td>0.025153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>https://www.nytimes.com/2022/10/27/technology/...</td>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>Amazon Returns to Growth but Signals Slowness ...</td>\n",
       "      <td>The results come amid a rocky patch for tech g...</td>\n",
       "      <td>['AMZN']</td>\n",
       "      <td>['Amazon.Com Inc.']</td>\n",
       "      <td>Financial Performance</td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.091115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4566 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    URL Publish Date  \\\n",
       "0     https://www.nytimes.com/2019/01/01/business/me...   2019-01-01   \n",
       "1     https://www.nytimes.com/2019/01/02/business/ju...   2019-01-02   \n",
       "2     https://www.nytimes.com/2019/01/02/business/te...   2019-01-02   \n",
       "3     https://www.nytimes.com/2019/01/03/business/de...   2019-01-03   \n",
       "4     https://www.nytimes.com/2019/01/03/business/de...   2019-01-03   \n",
       "...                                                 ...          ...   \n",
       "4800  https://www.nytimes.com/2022/10/18/technology/...   2022-10-18   \n",
       "4801  https://www.nytimes.com/2022/10/20/technology/...   2022-10-20   \n",
       "4802  https://www.nytimes.com/2022/10/25/technology/...   2022-10-25   \n",
       "4803  https://www.nytimes.com/2022/10/27/technology/...   2022-10-27   \n",
       "4804  https://www.nytimes.com/2022/10/27/technology/...   2022-10-27   \n",
       "\n",
       "                                                  Title  \\\n",
       "0     Netflix Blocks Show in Saudi Arabia Critical o...   \n",
       "1     Julie Sweet of Accenture Could See Her Future....   \n",
       "2     Tesla Reports Record Output, but Cuts Prices, ...   \n",
       "3     Bristol-Myers to Acquire Celgene in Deal Worth...   \n",
       "4     Was Apple’s Warning a Surprise? Not to Its Sup...   \n",
       "...                                                 ...   \n",
       "4800  Amazon Labor Union Loses Election at Warehouse...   \n",
       "4801  Texas Sues Google for Collecting Biometric Dat...   \n",
       "4802  Microsoft Reports Slowest Revenue Growth in Fi...   \n",
       "4803  Apple’s iPhone Powers Growth, but Signs Point ...   \n",
       "4804  Amazon Returns to Growth but Signals Slowness ...   \n",
       "\n",
       "                                              Main Text    Ticker  \\\n",
       "0     Netflix has blocked an episode of its show “Pa...  ['NFLX']   \n",
       "1     Why did you go to law school?\\n \\n I decided t...   ['ACN']   \n",
       "2     Tesla shares ended trading nearly 7 percent lo...  ['TSLA']   \n",
       "3     Bristol-Myers Squibb said on Thursday that it ...   ['BMY']   \n",
       "4     Apple’s stock fell 10 percent on Thursday, its...  ['AAPL']   \n",
       "...                                                 ...       ...   \n",
       "4800  Mr. Smalls said the election “wasn’t free and ...  ['AMZN']   \n",
       "4801  José Castañeda, a Google spokesman, said in a ...  ['GOOG']   \n",
       "4802  In the most recent quarter, softness in the gl...  ['MSFT']   \n",
       "4803  When Apple released the 16th version of its iP...  ['AAPL']   \n",
       "4804  The results come amid a rocky patch for tech g...  ['AMZN']   \n",
       "\n",
       "                    Description              News Type Sentiment  \\\n",
       "0               ['Netflix Inc']                    ESG  Negative   \n",
       "1     ['Accenture Plc Class A']                Non-ESG  Positive   \n",
       "2                 ['Tesla Inc']  Financial Performance  Negative   \n",
       "3      ['Bristol Myers Squibb']  Financial Performance   Neutral   \n",
       "4                 ['Apple Inc']  Financial Performance  Negative   \n",
       "...                         ...                    ...       ...   \n",
       "4800        ['Amazon.Com Inc.']                    ESG  Positive   \n",
       "4801   ['Alphabet Inc Class C']                    ESG  Negative   \n",
       "4802         ['Microsoft Corp']  Financial Performance  Positive   \n",
       "4803              ['Apple Inc']  Financial Performance  Positive   \n",
       "4804        ['Amazon.Com Inc.']  Financial Performance  Negative   \n",
       "\n",
       "      Date Comparison  Investor Reaction  Positive Consumer Perception  \\\n",
       "0                True           0.064605                     -0.025613   \n",
       "1                True          -0.001291                     -0.025522   \n",
       "2                True          -0.010247                     -0.004269   \n",
       "3                True          -0.059849                           NaN   \n",
       "4                True          -0.027306                      0.000000   \n",
       "...               ...                ...                           ...   \n",
       "4800             True           0.010129                      0.000000   \n",
       "4801             True          -0.040082                      0.032693   \n",
       "4802             True          -0.036752                     -0.036672   \n",
       "4803             True          -0.003742                     -0.036672   \n",
       "4804             True          -0.091115                           NaN   \n",
       "\n",
       "      Negative Consumer Perception  \n",
       "0                         0.019053  \n",
       "1                         0.007074  \n",
       "2                        -0.009292  \n",
       "3                              NaN  \n",
       "4                         0.000000  \n",
       "...                            ...  \n",
       "4800                      0.000000  \n",
       "4801                     -0.005359  \n",
       "4802                      0.025153  \n",
       "4803                      0.025153  \n",
       "4804                           NaN  \n",
       "\n",
       "[4566 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cd68d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_csv('Composed_Data_ver0.4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8b47b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
