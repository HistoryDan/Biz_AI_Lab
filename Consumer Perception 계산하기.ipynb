{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d301ba9f",
   "metadata": {},
   "source": [
    "# Consumer Perception 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5db7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91d642d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/06. 회귀분석 데이터/Composed_Data_ver1.2.csv',index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07648400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# companies = os.listdir('/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/02. Selected Data')\n",
    "# companies.remove('.DS_Store')\n",
    "# len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef167e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_df['Positive Consumer Perception'] = 0\n",
    "news_df['Negative Consumer Perception'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc97c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_path = '/Users/parkjunhyeong/Desktop/박준형/02. 대내 및 대외활동/01. 대내활동/03. Biz&AI 랩/02. 소스/01. 데이터/03. 트위터 데이터/02. Selected Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a06d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 220/220 [5:24:12<00:00, 88.42s/it]\n"
     ]
    }
   ],
   "source": [
    "total = pd.DataFrame()\n",
    "for company in tqdm(companies):\n",
    "    df = pd.read_csv(twitter_path + '/' + company, lineterminator = '\\n', index_col = 0)\n",
    "    df['Ticker'] = company[:-4]\n",
    "    total = pd.concat([total, df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43af8296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                  0\n",
       "username                  0\n",
       "content                   0\n",
       "clean_content             0\n",
       "sentiment                 0\n",
       "sentiment_score           0\n",
       "positive                  0\n",
       "neutral                   0\n",
       "negative            4999983\n",
       "Ticker                    0\n",
       "negative\\r         37366964\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fb7e528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>negative\\r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 03:01:19+00:00</td>\n",
       "      <td>ccie32305</td>\n",
       "      <td>@Cisco ... And hopefully stable Software...</td>\n",
       "      <td>@user ... And hopefully stable Software...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.764981</td>\n",
       "      <td>0.771661</td>\n",
       "      <td>0.221658</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 03:07:11+00:00</td>\n",
       "      <td>JussiKiviniemi</td>\n",
       "      <td>Looking back, 2017 was a pretty busy year work...</td>\n",
       "      <td>Looking back, 2017 was a pretty busy year work...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.627281</td>\n",
       "      <td>0.633567</td>\n",
       "      <td>0.360147</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 04:33:49+00:00</td>\n",
       "      <td>jitcompile</td>\n",
       "      <td>Personally a new beginning for me. I'm officia...</td>\n",
       "      <td>Personally a new beginning for me. I'm officia...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.941563</td>\n",
       "      <td>0.943016</td>\n",
       "      <td>0.055531</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 05:04:50+00:00</td>\n",
       "      <td>noorav</td>\n",
       "      <td>@jitcompile @Cisco Congratulations to you and ...</td>\n",
       "      <td>@user @user Congratulations to you and the @us...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.978864</td>\n",
       "      <td>0.982294</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 05:10:31+00:00</td>\n",
       "      <td>dpp</td>\n",
       "      <td>@jonoabroad @johndunham @Cisco You, too!</td>\n",
       "      <td>@user @user @user You, too!</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.685107</td>\n",
       "      <td>0.690733</td>\n",
       "      <td>0.303641</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42366942</th>\n",
       "      <td>2022-10-11 23:54:58+00:00</td>\n",
       "      <td>RyanfromOttawa</td>\n",
       "      <td>@Roku what gives with the channel??</td>\n",
       "      <td>@user what gives with the channel??</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.222829</td>\n",
       "      <td>0.009584</td>\n",
       "      <td>0.758004</td>\n",
       "      <td>0.232412</td>\n",
       "      <td>ROKU</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42366943</th>\n",
       "      <td>2022-10-11 23:55:46+00:00</td>\n",
       "      <td>330evertonian</td>\n",
       "      <td>@MichaelLikesItt @Roku Same for me.</td>\n",
       "      <td>@user @user Same for me.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.047944</td>\n",
       "      <td>0.065033</td>\n",
       "      <td>0.917877</td>\n",
       "      <td>0.017090</td>\n",
       "      <td>ROKU</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42366944</th>\n",
       "      <td>2022-10-11 23:56:07+00:00</td>\n",
       "      <td>ThaRealTBabe</td>\n",
       "      <td>@gasawaymusic @Roku It’s is down nothing is wo...</td>\n",
       "      <td>@user @user It’s is down nothing is working</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.877840</td>\n",
       "      <td>0.011022</td>\n",
       "      <td>0.100115</td>\n",
       "      <td>0.888862</td>\n",
       "      <td>ROKU</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42366945</th>\n",
       "      <td>2022-10-11 23:58:13+00:00</td>\n",
       "      <td>ROI__TV</td>\n",
       "      <td>Busting some #myths on #529Plans on @cunningha...</td>\n",
       "      <td>Busting some #myths on #529Plans on @user epis...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.083272</td>\n",
       "      <td>0.105359</td>\n",
       "      <td>0.872553</td>\n",
       "      <td>0.022088</td>\n",
       "      <td>ROKU</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42366946</th>\n",
       "      <td>2022-10-11 23:59:52+00:00</td>\n",
       "      <td>RobertAllen76</td>\n",
       "      <td>@VKloida I highly recommend @Roku I've been ha...</td>\n",
       "      <td>@user I highly recommend @user I've been happy...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.986156</td>\n",
       "      <td>0.989189</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>ROKU</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42366947 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           datetime        username  \\\n",
       "0         2018-01-01 03:01:19+00:00       ccie32305   \n",
       "1         2018-01-01 03:07:11+00:00  JussiKiviniemi   \n",
       "2         2018-01-01 04:33:49+00:00      jitcompile   \n",
       "3         2018-01-01 05:04:50+00:00          noorav   \n",
       "4         2018-01-01 05:10:31+00:00             dpp   \n",
       "...                             ...             ...   \n",
       "42366942  2022-10-11 23:54:58+00:00  RyanfromOttawa   \n",
       "42366943  2022-10-11 23:55:46+00:00   330evertonian   \n",
       "42366944  2022-10-11 23:56:07+00:00    ThaRealTBabe   \n",
       "42366945  2022-10-11 23:58:13+00:00         ROI__TV   \n",
       "42366946  2022-10-11 23:59:52+00:00   RobertAllen76   \n",
       "\n",
       "                                                    content  \\\n",
       "0               @Cisco ... And hopefully stable Software...   \n",
       "1         Looking back, 2017 was a pretty busy year work...   \n",
       "2         Personally a new beginning for me. I'm officia...   \n",
       "3         @jitcompile @Cisco Congratulations to you and ...   \n",
       "4                  @jonoabroad @johndunham @Cisco You, too!   \n",
       "...                                                     ...   \n",
       "42366942                @Roku what gives with the channel??   \n",
       "42366943                @MichaelLikesItt @Roku Same for me.   \n",
       "42366944  @gasawaymusic @Roku It’s is down nothing is wo...   \n",
       "42366945  Busting some #myths on #529Plans on @cunningha...   \n",
       "42366946  @VKloida I highly recommend @Roku I've been ha...   \n",
       "\n",
       "                                              clean_content sentiment  \\\n",
       "0                @user ... And hopefully stable Software...  positive   \n",
       "1         Looking back, 2017 was a pretty busy year work...  positive   \n",
       "2         Personally a new beginning for me. I'm officia...  positive   \n",
       "3         @user @user Congratulations to you and the @us...  positive   \n",
       "4                               @user @user @user You, too!  positive   \n",
       "...                                                     ...       ...   \n",
       "42366942                @user what gives with the channel??   neutral   \n",
       "42366943                           @user @user Same for me.   neutral   \n",
       "42366944        @user @user It’s is down nothing is working  negative   \n",
       "42366945  Busting some #myths on #529Plans on @user epis...   neutral   \n",
       "42366946  @user I highly recommend @user I've been happy...  positive   \n",
       "\n",
       "          sentiment_score  positive   neutral  negative Ticker  negative\\r  \n",
       "0                0.764981  0.771661  0.221658  0.006681   CSCO         NaN  \n",
       "1                0.627281  0.633567  0.360147  0.006286   CSCO         NaN  \n",
       "2                0.941563  0.943016  0.055531  0.001453   CSCO         NaN  \n",
       "3                0.978864  0.982294  0.014276  0.003430   CSCO         NaN  \n",
       "4                0.685107  0.690733  0.303641  0.005626   CSCO         NaN  \n",
       "...                   ...       ...       ...       ...    ...         ...  \n",
       "42366942        -0.222829  0.009584  0.758004  0.232412   ROKU         NaN  \n",
       "42366943         0.047944  0.065033  0.917877  0.017090   ROKU         NaN  \n",
       "42366944        -0.877840  0.011022  0.100115  0.888862   ROKU         NaN  \n",
       "42366945         0.083272  0.105359  0.872553  0.022088   ROKU         NaN  \n",
       "42366946         0.986156  0.989189  0.007778  0.003033   ROKU         NaN  \n",
       "\n",
       "[42366947 rows x 11 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5045eb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006680563557893"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_n.iloc[0,-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39d3beda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 42366947/42366947 [38:31<00:00, 18332.02it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(total_n))):\n",
    "    if total_n.iloc[i].isna()['negative\\r'] == False:\n",
    "        total_n.iloc[i,-3] = total_n.iloc[i,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "513e8485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_n['negative'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b59a39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_n.drop('negative\\r', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8153349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 42366947/42366947 [00:32<00:00, 1292239.52it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "total_n['datetime'] = total_n['datetime'].progress_apply(lambda x : x[:-15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41153177",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_n.to_csv('/Users/parkjunhyeong/Desktop/twitter_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0a2266b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 42366947/42366947 [00:43<00:00, 970795.33it/s]\n"
     ]
    }
   ],
   "source": [
    "def date_transform(x):\n",
    "    return datetime(int(x[:4]), int(x[5:7]), int(x[8:]))\n",
    "\n",
    "total_n['datetime'] = total_n['datetime'].progress_apply(lambda x: date_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f41178aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42366947 entries, 0 to 42366946\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   datetime         datetime64[ns]\n",
      " 1   username         object        \n",
      " 2   content          object        \n",
      " 3   clean_content    object        \n",
      " 4   sentiment        object        \n",
      " 5   sentiment_score  float64       \n",
      " 6   positive         float64       \n",
      " 7   neutral          float64       \n",
      " 8   negative         float64       \n",
      " 9   Ticker           object        \n",
      "dtypes: datetime64[ns](1), float64(4), object(5)\n",
      "memory usage: 3.2+ GB\n"
     ]
    }
   ],
   "source": [
    "total_n.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a50803e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4561/4561 [1:40:28<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(news_df))):\n",
    "    try:\n",
    "        ticker = news_df.loc[i, 'Ticker'][2:-2]\n",
    "        publish_date = news_df.loc[i, 'Publish Date'].split('.')\n",
    "        twitter_df = total_n[total_n['Ticker'] == ticker]\n",
    "\n",
    "        #15일간의 Positive, Negative Sentiment 확률의 평균값 구하기\n",
    "        start_date1 = (datetime(int(publish_date[0]), int(publish_date[1]), int(publish_date[2])) + timedelta(days = 0))\n",
    "        end_date1 = (datetime(int(publish_date[0]), int(publish_date[1]), int(publish_date[2])) + timedelta(days = 14))\n",
    "        sent_df1 = twitter_df[(start_date1 <= twitter_df['datetime']) & (twitter_df['datetime'] <= end_date1)]\n",
    "        average_pos1 = sent_df1['positive'].mean()\n",
    "        average_neg1 = sent_df1['negative'].mean()\n",
    "\n",
    "        #t-130일부터 t-30일의 Positive, Negative Sentiment 확률의 평균값 구하기\n",
    "        start_date2 = (datetime(int(publish_date[0]), int(publish_date[1]), int(publish_date[2])) + timedelta(days = -30))\n",
    "        end_date2 = (datetime(int(publish_date[0]), int(publish_date[1]), int(publish_date[2])) + timedelta(days = -130))\n",
    "        sent_df2 = twitter_df[(end_date2 <= twitter_df['datetime']) & (twitter_df['datetime'] <= start_date2)]\n",
    "        average_pos2 = sent_df2['positive'].mean()\n",
    "        average_neg2 = sent_df2['negative'].mean()\n",
    "        \n",
    "        news_df.loc[i,'Positive Consumer Perception'] = average_pos1 - average_pos2\n",
    "        news_df.loc[i,'Negative Consumer Perception'] = average_neg1 - average_neg2    \n",
    "                \n",
    "    except Exception as e :\n",
    "        print(ticker, publish_date)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cad9cc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL                              0\n",
       "Publish Date                     0\n",
       "Title                            0\n",
       "Main Text                        2\n",
       "Ticker                           0\n",
       "Description                      0\n",
       "News Type                        0\n",
       "Sentiment                        0\n",
       "Investor Reaction                0\n",
       "GICS Sectors                     0\n",
       "Firm Age                         0\n",
       "Twitter Followers                0\n",
       "Total Asset                      0\n",
       "ROA                              0\n",
       "Positive Consumer Perception    84\n",
       "Negative Consumer Perception    84\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.isnull().s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "273bfbd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 5/4561 [00:15<3:15:34,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL 2019-01-03\n",
      "'negative'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                        | 6/4561 [00:21<4:37:04,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFLX 2019-01-06\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 7/4561 [00:22<4:07:54,  3.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m calculation_date \u001b[38;5;241m=\u001b[39m (datetime(\u001b[38;5;28mint\u001b[39m(publish_date[:\u001b[38;5;241m4\u001b[39m]), \u001b[38;5;28mint\u001b[39m(publish_date[\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m7\u001b[39m]), \u001b[38;5;28mint\u001b[39m(publish_date[\u001b[38;5;241m8\u001b[39m:\u001b[38;5;241m10\u001b[39m])) \u001b[38;5;241m+\u001b[39m timedelta(days \u001b[38;5;241m=\u001b[39m j))\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m pos_sentiment \u001b[38;5;241m=\u001b[39m twitter_df[twitter_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m calculation_date][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 23\u001b[0m neg_sentiment \u001b[38;5;241m=\u001b[39m twitter_df[\u001b[43mtwitter_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcalculation_date\u001b[49m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     24\u001b[0m cp_pos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pos_sentiment\n\u001b[1;32m     25\u001b[0m cp_neg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m neg_sentiment\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:5623\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5620\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 5623\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:283\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:73\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for i in tqdm(range(len(news_df))):\n",
    "#     try:\n",
    "#         ticker = news_df.loc[i, 'Ticker'][2:-2]\n",
    "#         publish_date = news_df.loc[i, 'Publish Date']\n",
    "#         #트위터 데이터에서 필요 정보 가져오기\n",
    "#         twitter_df = pd.read_csv(twitter_path + '/' + ticker + '.csv', lineterminator = '\\n')\n",
    "# #         for i in range(len(twitter_df)):\n",
    "# #             try:\n",
    "# #                 twitter_df.iloc[i,1] = twitter_df.iloc[i,1][:-15]\n",
    "# #             except:\n",
    "# #                 pass\n",
    "#         twitter_df['datetime'] = twitter_df['datetime'].apply(lambda x : x[:-15])\n",
    "#         #news publish date와 일치하는 트위터 게시일이 있는 경우\n",
    "#         if publish_date in list(twitter_df['datetime']):\n",
    "#             cp_pos = 0\n",
    "#             cp_neg = 0\n",
    "#             average_pos = 0\n",
    "#             average_neg = 0\n",
    "#             for j in range(15):\n",
    "#                 #15일간의 Positive 확률의 평균값 구하기\n",
    "#                 calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = j)).strftime(\"%Y-%m-%d\")\n",
    "#                 pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "#                 neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "#                 cp_pos += pos_sentiment\n",
    "#                 cp_neg += neg_sentiment\n",
    "#             for j in range(100):\n",
    "#                 calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = -30 - j)).strftime(\"%Y-%m-%d\")\n",
    "#                 pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "#                 neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "#                 average_pos += pos_sentiment\n",
    "#                 average_neg += neg_sentiment\n",
    "#             cp_pos /= 15\n",
    "#             cp_neg /= 15\n",
    "#             average_pos /= 100\n",
    "#             average_neg /= 100\n",
    "#             cp_pos = cp_pos - average_pos\n",
    "#             cp_neg = cp_neg - average_neg\n",
    "#         #news publish date와 일치하는 트위터 게시일이 없는 경우\n",
    "#         else:\n",
    "#             publish_datetime = datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10]))\n",
    "#             for k in range(30):\n",
    "#                 if (publish_datetime + timedelta(days = k)).strftime(\"%Y-%m-%d\") in list(twitter_df['datetime']):\n",
    "#                     publish_date = (publish_datetime + timedelta(days = k)).strftime(\"%Y-%m-%d\")\n",
    "#                     break\n",
    "#             cp_pos = 0\n",
    "#             cp_neg = 0\n",
    "#             for j in range(1000):\n",
    "#                 #15일간의 Positive 확률의 평균값 구하기\n",
    "#                 calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = j)).strftime(\"%Y-%m-%d\")\n",
    "#                 pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "#                 neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "#                 cp_pos += pos_sentiment\n",
    "#                 cp_neg += neg_sentiment\n",
    "#             for j in range(100):\n",
    "#                 calculation_date = (datetime(int(publish_date[:4]), int(publish_date[5:7]), int(publish_date[8:10])) + timedelta(days = -30 - j)).strftime(\"%Y-%m-%d\")\n",
    "#                 pos_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['positive'].mean()\n",
    "#                 neg_sentiment = twitter_df[twitter_df['datetime'] == calculation_date]['negative'].mean()\n",
    "#                 average_pos += pos_sentiment\n",
    "#                 average_neg += neg_sentiment\n",
    "#             cp_pos /= 15\n",
    "#             cp_neg /= 15\n",
    "#             average_pos /= 100\n",
    "#             average_neg /= 100\n",
    "#             cp_pos = cp_pos - average_pos\n",
    "#             cp_neg = cp_neg - average_neg\n",
    "#         news_df.iloc[i,-1] = cp_neg\n",
    "#         news_df.iloc[i,-2] = cp_pos\n",
    "                \n",
    "#     except Exception as e :\n",
    "#         print(ticker, publish_date)\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4cd68d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_csv('/Users/parkjunhyeong/Desktop/Composed_Data_ver1.3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "69a8b47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12593548</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Tony_PharmD</td>\n",
       "      <td>How to Pronounce Drug Names Audiobook No more ...</td>\n",
       "      <td>How to Pronounce Drug Names Audiobook No more ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>0.891910</td>\n",
       "      <td>0.017846</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12593549</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>MountainLamb</td>\n",
       "      <td>Just saw this on Amazon: When Night Comes (Jac...</td>\n",
       "      <td>Just saw this on Amazon: When Night Comes (Jac...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.111198</td>\n",
       "      <td>0.114454</td>\n",
       "      <td>0.882290</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12593550</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>vipcoupons4u</td>\n",
       "      <td>BEST Men Novelty Slack Socks - Perfect for Sty...</td>\n",
       "      <td>BEST Men Novelty Slack Socks - Perfect for Sty...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.896812</td>\n",
       "      <td>0.899617</td>\n",
       "      <td>0.097579</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12593551</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>davidevas82</td>\n",
       "      <td>#publishing For a Responsible Economy Youcanpr...</td>\n",
       "      <td>#publishing For a Responsible Economy Youcanpr...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.346402</td>\n",
       "      <td>0.353830</td>\n",
       "      <td>0.638742</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12593552</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>dustinmvang</td>\n",
       "      <td>@DreamCreeper66 @amazon No problem! Good luck ...</td>\n",
       "      <td>@user @user No problem! Good luck lets see you...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.981384</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093543</th>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>Sunshine_blue2</td>\n",
       "      <td>@cxcruz1 @fmqblaw @DavidBegnaud @amazon They h...</td>\n",
       "      <td>@user @user @user @user They have restrictions...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.243664</td>\n",
       "      <td>0.022750</td>\n",
       "      <td>0.710836</td>\n",
       "      <td>0.266414</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093544</th>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>rapturefish</td>\n",
       "      <td>@longshotauthor @amazon Wait… what, you have a...</td>\n",
       "      <td>@user @user Wait… what, you have a SON!? Who W...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.978867</td>\n",
       "      <td>0.981049</td>\n",
       "      <td>0.016770</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093545</th>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>LunchLadiesBC</td>\n",
       "      <td>Author Spotlight\\n\\nE.H. VICK specializes in p...</td>\n",
       "      <td>Author Spotlight  E.H. VICK specializes in pul...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.100173</td>\n",
       "      <td>0.142378</td>\n",
       "      <td>0.815417</td>\n",
       "      <td>0.042205</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093546</th>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>howtheturntblz</td>\n",
       "      <td>@IsIllinois @JBPritzker @amazon When profit tr...</td>\n",
       "      <td>@user @user @user When profit trumps basic hum...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.682046</td>\n",
       "      <td>0.015091</td>\n",
       "      <td>0.287772</td>\n",
       "      <td>0.697137</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093547</th>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>airsoftkumasan1</td>\n",
       "      <td>Australian Classic Gourmet Gift Basket - Colle...</td>\n",
       "      <td>Australian Classic Gourmet Gift Basket - Colle...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.928916</td>\n",
       "      <td>0.931031</td>\n",
       "      <td>0.066853</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime         username  \\\n",
       "12593548 2018-01-01      Tony_PharmD   \n",
       "12593549 2018-01-01     MountainLamb   \n",
       "12593550 2018-01-01     vipcoupons4u   \n",
       "12593551 2018-01-01      davidevas82   \n",
       "12593552 2018-01-01      dustinmvang   \n",
       "...             ...              ...   \n",
       "13093543 2022-10-11   Sunshine_blue2   \n",
       "13093544 2022-10-11      rapturefish   \n",
       "13093545 2022-10-11    LunchLadiesBC   \n",
       "13093546 2022-10-11   howtheturntblz   \n",
       "13093547 2022-10-11  airsoftkumasan1   \n",
       "\n",
       "                                                    content  \\\n",
       "12593548  How to Pronounce Drug Names Audiobook No more ...   \n",
       "12593549  Just saw this on Amazon: When Night Comes (Jac...   \n",
       "12593550  BEST Men Novelty Slack Socks - Perfect for Sty...   \n",
       "12593551  #publishing For a Responsible Economy Youcanpr...   \n",
       "12593552  @DreamCreeper66 @amazon No problem! Good luck ...   \n",
       "...                                                     ...   \n",
       "13093543  @cxcruz1 @fmqblaw @DavidBegnaud @amazon They h...   \n",
       "13093544  @longshotauthor @amazon Wait… what, you have a...   \n",
       "13093545  Author Spotlight\\n\\nE.H. VICK specializes in p...   \n",
       "13093546  @IsIllinois @JBPritzker @amazon When profit tr...   \n",
       "13093547  Australian Classic Gourmet Gift Basket - Colle...   \n",
       "\n",
       "                                              clean_content sentiment  \\\n",
       "12593548  How to Pronounce Drug Names Audiobook No more ...   neutral   \n",
       "12593549  Just saw this on Amazon: When Night Comes (Jac...   neutral   \n",
       "12593550  BEST Men Novelty Slack Socks - Perfect for Sty...  positive   \n",
       "12593551  #publishing For a Responsible Economy Youcanpr...   neutral   \n",
       "12593552  @user @user No problem! Good luck lets see you...  positive   \n",
       "...                                                     ...       ...   \n",
       "13093543  @user @user @user @user They have restrictions...   neutral   \n",
       "13093544  @user @user Wait… what, you have a SON!? Who W...  positive   \n",
       "13093545  Author Spotlight  E.H. VICK specializes in pul...   neutral   \n",
       "13093546  @user @user @user When profit trumps basic hum...  negative   \n",
       "13093547  Australian Classic Gourmet Gift Basket - Colle...  positive   \n",
       "\n",
       "          sentiment_score  positive   neutral  negative Ticker  \n",
       "12593548         0.072398  0.090244  0.891910  0.017846   AMZN  \n",
       "12593549         0.111198  0.114454  0.882290  0.003256   AMZN  \n",
       "12593550         0.896812  0.899617  0.097579  0.002804   AMZN  \n",
       "12593551         0.346402  0.353830  0.638742  0.007428   AMZN  \n",
       "12593552         0.978763  0.981384  0.015996  0.002621   AMZN  \n",
       "...                   ...       ...       ...       ...    ...  \n",
       "13093543        -0.243664  0.022750  0.710836  0.266414   AMZN  \n",
       "13093544         0.978867  0.981049  0.016770  0.002181   AMZN  \n",
       "13093545         0.100173  0.142378  0.815417  0.042205   AMZN  \n",
       "13093546        -0.682046  0.015091  0.287772  0.697137   AMZN  \n",
       "13093547         0.928916  0.931031  0.066853  0.002115   AMZN  \n",
       "\n",
       "[500000 rows x 10 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7126a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
